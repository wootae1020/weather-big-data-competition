{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5e892b-5b61-4ece-a669-60cb8b27c35a",
   "metadata": {},
   "source": [
    "### 베이스라인 모델은 다음과 같은 이유로 선정하였습니다.\n",
    "- 데이터 특성 상, 피처가 많아 다중공선성의 위험이 있고, 범주형 변수가 많았습니다.\n",
    "- 따라서, 다중공선성에 강하고 규제화가 잘 되며 범주형 변수에 강한 모델을 선정하였습니다.\n",
    "  \n",
    "- **ARDRegression**\n",
    "특징: 각 특성(feature)에 대해 별도의 정규화 강도를 추정해 불필요한 변수를 자동으로 축소(/제거)  \n",
    "장점: 다중공선성(collinearity)에 강하며, 모델 간결성 유지  \n",
    "\n",
    "- **XGBRegressor**\n",
    "특징: 트리 기반 GBM의 최적화판, 병렬 학습·정규화·결측 처리 내장  \n",
    "장점: 속도·성능 우수, 과적합 제어용 파라미터 풍부, n_jobs 지원  \n",
    "\n",
    "- **LGBMRegressor**\n",
    "특징: histogram 기반, 잎 중심(leaf-wise) 분할 → 대용량 데이터에 빠름  \n",
    "장점: 메모리 효율·학습 속도 우수, n_jobs 지원  \n",
    "\n",
    "- **CatBoostRegressor**\n",
    "특징: 범주형 변수를 별도 전처리 없이 자동 처리, ordered boosting으로 과적합 억제  \n",
    "장점: 범주형 데이터 다룰 때 성능·편의성 우수, 튜닝 부담 비교적 낮음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e470de65-a5fa-4ca8-8ead-c2a444b8a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\n",
    "    'data.parquet',\n",
    "    engine='pyarrow'         # 저장 시 사용한 엔진과 동일하게 지정\n",
    ")\n",
    "test_loaded = pd.read_parquet(\n",
    "    'test.parquet',\n",
    "    engine='pyarrow'         # 저장 시 사용한 엔진과 동일하게 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45867028-42fe-4443-9bc0-7de97358027c",
   "metadata": {},
   "source": [
    "# 대회 공지사항에 따라 df 이상치 드롭\n",
    "- 남위례를 제외한 한대앞~오이도역 구간은 내부 프로그램 오류로 인하여 22년 6월 13일까지 4호선 재차인원이 누락되었습니다. \n",
    "- 해당기간동안 한대앞~오이도역을 이용하는 인원은 모두 수인분당선을 이용하는것으로 기록되었습니다.\n",
    "- 남위례역은 21년 12월 18일에 개통하였으며, 프로그램 내부에 개통사항 반영이 늦어져 혼잡도가 0으로 산출된 것으로 확인됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7f0edc-bd3b-4240-b78f-e970d98c284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature / target 정의\n",
    "ordered_cols = ['Direction', 'time_period']\n",
    "cat_cols     = [\n",
    "                'station_number'\n",
    "                , 'address'\n",
    "               ] + ordered_cols\n",
    "num_cols = [\n",
    "    'HM','RN_DAY','RN_HR1',\n",
    "    'TA','WD','WS'\n",
    "    ,'STN'\n",
    "    ,'sin_dom','cos_dom','sin_dow','cos_dow','sin_hod','cos_hod'\n",
    "    ,'sin_wom','cos_wom','sin_woy','cos_woy','sin_doy','cos_doy'\n",
    "    ,'day','day_of_year','hour'\n",
    "    ,'is_day_before_holiday','is_day_after_holiday','is_holiday','is_weekend'\n",
    "    ,'month','transfer','week_of_month','week_of_year','weekday','year'\n",
    "    ,'신설역', '신규관측소'\n",
    "]\n",
    "feature_cols = num_cols + ordered_cols + cat_cols\n",
    "target_col   = 'Congestion'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311835f5-cb9c-4bc1-b31c-ce31b53613bc",
   "metadata": {},
   "source": [
    "# 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b1b1f6-82da-42b9-abc2-870fefebb24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_val)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    r2   = r2_score(y_val, y_pred)\n",
    "    \n",
    "    return {'Model': name, 'Time(s)': elapsed, 'RMSE': rmse, 'R2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee91caf-1094-4e95-bb21-1b53d3869ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Line 1] ARD: RMSE=15.080, R2=0.459, Time=180.7s\n",
      "[Line 1] XGB: RMSE=6.857, R2=0.888, Time=23.6s\n",
      "[Line 2] ARD: RMSE=15.616, R2=0.468, Time=146.2s\n",
      "[Line 2] XGB: RMSE=7.881, R2=0.864, Time=15.0s\n",
      "[Line 3] ARD: RMSE=13.590, R2=0.531, Time=123.6s\n",
      "[Line 3] XGB: RMSE=5.669, R2=0.918, Time=13.6s\n",
      "[Line 4] ARD: RMSE=15.093, R2=0.489, Time=321.0s\n",
      "[Line 4] XGB: RMSE=6.823, R2=0.896, Time=15.9s\n",
      "[Line 5] ARD: RMSE=13.581, R2=0.511, Time=105.1s\n",
      "[Line 5] XGB: RMSE=6.083, R2=0.902, Time=16.2s\n",
      "[Line 6] ARD: RMSE=11.456, R2=0.470, Time=52.3s\n",
      "[Line 6] XGB: RMSE=5.284, R2=0.887, Time=12.8s\n",
      "[Line 7] ARD: RMSE=17.961, R2=0.383, Time=149.1s\n",
      "[Line 7] XGB: RMSE=8.444, R2=0.864, Time=19.7s\n",
      "[Line 8] ARD: RMSE=15.102, R2=0.590, Time=25.6s\n",
      "[Line 8] XGB: RMSE=5.884, R2=0.938, Time=4.6s\n",
      "\n",
      "=== 전체 라인·모델별 실행 시간·성능 비교 ===\n",
      "   Model     Time(s)       RMSE        R2  Line\n",
      "0    ARD  180.651611  15.080387  0.459299     1\n",
      "1    XGB   23.625844   6.857039  0.888209     1\n",
      "2    ARD  146.226538  15.615536  0.467739     2\n",
      "3    XGB   14.984249   7.881420  0.864412     2\n",
      "4    ARD  123.554140  13.590160  0.530815     3\n",
      "5    XGB   13.642889   5.669039  0.918358     3\n",
      "6    ARD  321.007231  15.093386  0.488668     4\n",
      "7    XGB   15.922182   6.822502  0.895524     4\n",
      "8    ARD  105.108774  13.580593  0.510768     5\n",
      "9    XGB   16.166192   6.082528  0.901860     5\n",
      "10   ARD   52.288889  11.456016  0.470489     6\n",
      "11   XGB   12.795033   5.284143  0.887343     6\n",
      "12   ARD  149.103038  17.960513  0.383249     7\n",
      "13   XGB   19.705814   8.444309  0.863667     7\n",
      "14   ARD   25.561524  15.102293  0.590000     8\n",
      "15   XGB    4.607764   5.884100  0.937762     8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리·평가용\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics      import mean_squared_error, r2_score\n",
    "\n",
    "# ── 선형 계열 회귀 모델 ──\n",
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "# ── 트리 & 앙상블 ──\n",
    "from sklearn.ensemble      import (\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor\n",
    ")\n",
    "\n",
    "# ── 신경망 & 부스팅 ──\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost                 import XGBRegressor\n",
    "from lightgbm                import LGBMRegressor\n",
    "from catboost                import CatBoostRegressor\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 미리 정의해야 할 변수\n",
    "# df: 학습용 DataFrame (컬럼에 'Line', 'TM', STN, address, feature_cols, target_col 포함)\n",
    "# test: 테스트용 DataFrame (컬럼 구조 동일)\n",
    "# feature_cols: predictor로 사용할 컬럼 리스트\n",
    "# target_col: 예측 대상 컬럼 이름 (문자열)\n",
    "# cat_cols: 범주형으로 one-hot encoding 할 컬럼 리스트 (예: ['STN','address'])\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Time(s)': time.time() - t0,\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),\n",
    "        'R2': r2_score(y_val, y_pred)\n",
    "    }\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for line in range(1, 9):\n",
    "    # 1) subset & sort\n",
    "    df_line   = df [df['Line']==line].sort_values('TM').copy()\n",
    "    test_line = test_loaded[test_loaded['Line']==line].copy()\n",
    "\n",
    "    # 2) 카테고리 지정\n",
    "    for col in cat_cols:\n",
    "        df_line[col]   = df_line[col].astype('category')\n",
    "        test_line[col] = test_line[col].astype('category')\n",
    "\n",
    "    # 3) feature & target\n",
    "    X      = df_line[feature_cols]\n",
    "    y      = df_line[target_col].astype(int)\n",
    "    X_test = test_line[feature_cols]\n",
    "\n",
    "    # 4) 원-핫 인코딩\n",
    "    X_enc      = pd.get_dummies(X,      columns=cat_cols, drop_first=False)\n",
    "    X_test_enc = pd.get_dummies(X_test, columns=cat_cols, drop_first=False)\n",
    "\n",
    "    # 5) 중복 컬럼 제거 & 정렬, 누락 채움\n",
    "    X_enc      = X_enc.loc[:, ~X_enc.columns.duplicated()]\n",
    "    X_test_enc = X_test_enc.loc[:, ~X_test_enc.columns.duplicated()]\n",
    "    X_test_enc = X_test_enc.reindex(columns=X_enc.columns, fill_value=0)\n",
    "\n",
    "    # 6) 정규화\n",
    "    mm             = MinMaxScaler()\n",
    "    X_scaled       = mm.fit_transform(X_enc)\n",
    "    X_test_scaled  = mm.transform(X_test_enc)\n",
    "\n",
    "    # 7) 시간 순 분할 (train:val = 8:2)\n",
    "    split_idx = int(len(X_scaled) * 0.8)\n",
    "    X_train, X_val = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "    y_train, y_val = y.values[:split_idx],    y.values[split_idx:]\n",
    "\n",
    "    # 8) 모델별 평가\n",
    "    for name, model in [\n",
    "        ('ARD',  ARDRegression()),\n",
    "        ('XGB',  XGBRegressor(tree_method='hist', n_jobs=-1, random_state=42)),\n",
    "        # ('LGBM', LGBMRegressor(n_jobs=-1, random_state=42)),\n",
    "        # ('CAT',  CatBoostRegressor(verbose=0, random_state=42))\n",
    "    ]:\n",
    "        res = evaluate_model(name, model, X_train, y_train, X_val, y_val)\n",
    "        res['Line'] = line\n",
    "        all_results.append(res)\n",
    "        print(f\"[Line {line}] {name}: RMSE={res['RMSE']:.3f}, R2={res['R2']:.3f}, Time={res['Time(s)']:.1f}s\")\n",
    "\n",
    "# 9) 종합 결과 DataFrame 생성 및 저장\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(\"\\n=== 전체 라인·모델별 실행 시간·성능 비교 ===\")\n",
    "print(results_df)\n",
    "\n",
    "# CSV로 저장 (필요시)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "results_df.to_csv('results/model_performance_all_lines.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
