{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e470de65-a5fa-4ca8-8ead-c2a444b8a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\n",
    "    'data.parquet',\n",
    "    engine='pyarrow'         # ì €ì¥ ì‹œ ì‚¬ìš©í•œ ì—”ì§„ê³¼ ë™ì¼í•˜ê²Œ ì§€ì •\n",
    ")\n",
    "test_loaded = pd.read_parquet(\n",
    "    'test.parquet',\n",
    "    engine='pyarrow'         # ì €ì¥ ì‹œ ì‚¬ìš©í•œ ì—”ì§„ê³¼ ë™ì¼í•˜ê²Œ ì§€ì •\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7f0edc-bd3b-4240-b78f-e970d98c284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature / target ì •ì˜\n",
    "ordered_cols = ['Direction', 'time_period']\n",
    "cat_cols     = [\n",
    "                'station_number'\n",
    "                , 'address'\n",
    "               # , 'station_name'\n",
    "               ] + ordered_cols\n",
    "num_cols = [\n",
    "    'HM','RN_DAY','RN_HR1',\n",
    "    #'SI',\n",
    "    'TA','WD','WS'\n",
    "    ,'STN'\n",
    "    ,'sin_dom','cos_dom','sin_dow','cos_dow','sin_hod','cos_hod'\n",
    "    ,'sin_wom','cos_wom','sin_woy','cos_woy','sin_doy','cos_doy'\n",
    "    ,'day','day_of_year','hour'\n",
    "    ,'is_day_before_holiday','is_day_after_holiday','is_holiday','is_weekend'\n",
    "    ,'month','transfer','week_of_month','week_of_year','weekday','year'\n",
    "    ,'ì‹ ì„¤ì—­', 'ì‹ ê·œê´€ì¸¡ì†Œ'\n",
    "]\n",
    "feature_cols = num_cols + ordered_cols + cat_cols\n",
    "target_col   = 'Congestion'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311835f5-cb9c-4bc1-b31c-ce31b53613bc",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b1b1f6-82da-42b9-abc2-870fefebb24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_val)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    r2   = r2_score(y_val, y_pred)\n",
    "    \n",
    "    return {'Model': name, 'Time(s)': elapsed, 'RMSE': rmse, 'R2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee91caf-1094-4e95-bb21-1b53d3869ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2251468, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 18.002817\n",
      "[Line 1] LGBM: RMSE=7.877, R2=0.852, Time=9.6s\n",
      "[Line 1] CAT: RMSE=5.479, R2=0.929, Time=255.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2542\n",
      "[LightGBM] [Info] Number of data points in the train set: 1596672, number of used features: 95\n",
      "[LightGBM] [Info] Start training from score 28.565433\n",
      "[Line 2] LGBM: RMSE=10.431, R2=0.762, Time=10.3s\n",
      "[Line 2] CAT: RMSE=11.665, R2=0.703, Time=177.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2553\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598990, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 19.906141\n",
      "[Line 3] LGBM: RMSE=5.820, R2=0.914, Time=10.0s\n",
      "[Line 3] CAT: RMSE=6.429, R2=0.895, Time=179.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2530\n",
      "[LightGBM] [Info] Number of data points in the train set: 1638761, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 21.225119\n",
      "[Line 4] LGBM: RMSE=7.913, R2=0.859, Time=8.4s\n",
      "[Line 4] CAT: RMSE=5.384, R2=0.935, Time=168.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2582\n",
      "[LightGBM] [Info] Number of data points in the train set: 1770249, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 20.651826\n",
      "[Line 5] LGBM: RMSE=7.170, R2=0.864, Time=8.3s\n",
      "[Line 5] CAT: RMSE=4.995, R2=0.934, Time=183.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2485\n",
      "[LightGBM] [Info] Number of data points in the train set: 1451520, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 15.109336\n",
      "[Line 6] LGBM: RMSE=6.808, R2=0.813, Time=6.9s\n",
      "[Line 6] CAT: RMSE=7.710, R2=0.760, Time=140.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2532\n",
      "[LightGBM] [Info] Number of data points in the train set: 1978368, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 23.131690\n",
      "[Line 7] LGBM: RMSE=9.992, R2=0.809, Time=9.5s\n",
      "[Line 7] CAT: RMSE=6.825, R2=0.911, Time=202.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2413\n",
      "[LightGBM] [Info] Number of data points in the train set: 629160, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 21.295373\n",
      "[Line 8] LGBM: RMSE=6.001, R2=0.935, Time=3.1s\n",
      "[Line 8] CAT: RMSE=4.620, R2=0.962, Time=59.2s\n",
      "\n",
      "=== ì „ì²´ ë¼ì¸Â·ëª¨ë¸ë³„ ì‹¤í–‰ ì‹œê°„Â·ì„±ëŠ¥ ë¹„êµ ===\n",
      "   Model     Time(s)       RMSE        R2  Line\n",
      "0   LGBM    9.604774   7.876524  0.852497     1\n",
      "1    CAT  255.308370   5.479455  0.928615     1\n",
      "2   LGBM   10.326076  10.431055  0.762498     2\n",
      "3    CAT  177.145799  11.665339  0.702966     2\n",
      "4   LGBM    9.955862   5.820142  0.913948     3\n",
      "5    CAT  179.791089   6.428667  0.895013     3\n",
      "6   LGBM    8.439031   7.912993  0.859456     4\n",
      "7    CAT  168.116032   5.384204  0.934931     4\n",
      "8   LGBM    8.282786   7.169554  0.863648     5\n",
      "9    CAT  183.700930   4.995188  0.933812     5\n",
      "10  LGBM    6.942290   6.808427  0.812974     6\n",
      "11   CAT  140.492593   7.710238  0.760148     6\n",
      "12  LGBM    9.452847   9.991821  0.809120     7\n",
      "13   CAT  202.591715   6.824788  0.910947     7\n",
      "14  LGBM    3.085980   6.000524  0.935274     8\n",
      "15   CAT   59.182165   4.619697  0.961636     8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ì „ì²˜ë¦¬Â·í‰ê°€ìš©\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics      import mean_squared_error, r2_score\n",
    "\n",
    "# â”€â”€ ì„ í˜• ê³„ì—´ íšŒê·€ ëª¨ë¸ â”€â”€\n",
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "# â”€â”€ íŠ¸ë¦¬ & ì•™ìƒë¸” â”€â”€\n",
    "from sklearn.ensemble      import (\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor\n",
    ")\n",
    "\n",
    "# â”€â”€ ì‹ ê²½ë§ & ë¶€ìŠ¤íŒ… â”€â”€\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost                 import XGBRegressor\n",
    "from lightgbm                import LGBMRegressor\n",
    "from catboost                import CatBoostRegressor\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# ë¯¸ë¦¬ ì •ì˜í•´ì•¼ í•  ë³€ìˆ˜\n",
    "# df: í•™ìŠµìš© DataFrame (ì»¬ëŸ¼ì— 'Line', 'TM', STN, address, feature_cols, target_col í¬í•¨)\n",
    "# test: í…ŒìŠ¤íŠ¸ìš© DataFrame (ì»¬ëŸ¼ êµ¬ì¡° ë™ì¼)\n",
    "# feature_cols: predictorë¡œ ì‚¬ìš©í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
    "# target_col: ì˜ˆì¸¡ ëŒ€ìƒ ì»¬ëŸ¼ ì´ë¦„ (ë¬¸ìì—´)\n",
    "# cat_cols: ë²”ì£¼í˜•ìœ¼ë¡œ one-hot encoding í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['STN','address'])\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Time(s)': time.time() - t0,\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),\n",
    "        'R2': r2_score(y_val, y_pred)\n",
    "    }\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for line in range(1, 9):\n",
    "    # 1) subset & sort\n",
    "    df_line   = df [df['Line']==line].sort_values('TM').copy()\n",
    "    test_line = test_loaded[test_loaded['Line']==line].copy()\n",
    "\n",
    "    # 2) ì¹´í…Œê³ ë¦¬ ì§€ì •\n",
    "    for col in cat_cols:\n",
    "        df_line[col]   = df_line[col].astype('category')\n",
    "        test_line[col] = test_line[col].astype('category')\n",
    "\n",
    "    # 3) feature & target\n",
    "    X      = df_line[feature_cols]\n",
    "    y      = df_line[target_col].astype(int)\n",
    "    X_test = test_line[feature_cols]\n",
    "\n",
    "    # 4) ì›-í•« ì¸ì½”ë”©\n",
    "    X_enc      = pd.get_dummies(X,      columns=cat_cols, drop_first=False)\n",
    "    X_test_enc = pd.get_dummies(X_test, columns=cat_cols, drop_first=False)\n",
    "\n",
    "    # 5) ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° & ì •ë ¬, ëˆ„ë½ ì±„ì›€\n",
    "    X_enc      = X_enc.loc[:, ~X_enc.columns.duplicated()]\n",
    "    X_test_enc = X_test_enc.loc[:, ~X_test_enc.columns.duplicated()]\n",
    "    X_test_enc = X_test_enc.reindex(columns=X_enc.columns, fill_value=0)\n",
    "\n",
    "    # 6) ì •ê·œí™”\n",
    "    mm             = MinMaxScaler()\n",
    "    X_scaled       = mm.fit_transform(X_enc)\n",
    "    X_test_scaled  = mm.transform(X_test_enc)\n",
    "\n",
    "    # 7) ì‹œê°„ ìˆœ ë¶„í•  (train:val = 8:2)\n",
    "    split_idx = int(len(X_scaled) * 0.8)\n",
    "    X_train, X_val = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "    y_train, y_val = y.values[:split_idx],    y.values[split_idx:]\n",
    "\n",
    "    # 8) ëª¨ë¸ë³„ í‰ê°€\n",
    "    for name, model in [\n",
    "\n",
    "        ('LGBM', LGBMRegressor(n_jobs=-1, random_state=42)),\n",
    "        ('CAT',  CatBoostRegressor(verbose=0, random_state=42))\n",
    "    ]:\n",
    "        res = evaluate_model(name, model, X_train, y_train, X_val, y_val)\n",
    "        res['Line'] = line\n",
    "        all_results.append(res)\n",
    "        print(f\"[Line {line}] {name}: RMSE={res['RMSE']:.3f}, R2={res['R2']:.3f}, Time={res['Time(s)']:.1f}s\")\n",
    "\n",
    "# 9) ì¢…í•© ê²°ê³¼ DataFrame ìƒì„± ë° ì €ì¥\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(\"\\n=== ì „ì²´ ë¼ì¸Â·ëª¨ë¸ë³„ ì‹¤í–‰ ì‹œê°„Â·ì„±ëŠ¥ ë¹„êµ ===\")\n",
    "print(results_df)\n",
    "\n",
    "# CSVë¡œ ì €ì¥ (í•„ìš”ì‹œ)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "results_df.to_csv('results/model_performance_all_lines.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa90bea-26d5-4071-b83c-4550701c78b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ARD', 'Time(s)': 112.8433210849762, 'RMSE': 17.95454833434004, 'R2': 0.38365889038325696}\n",
      "{'Model': 'RF', 'Time(s)': 786.7618379592896, 'RMSE': 6.940728451896612, 'R2': 0.9078951978696133}\n",
      "{'Model': 'ET', 'Time(s)': 737.5762186050415, 'RMSE': 6.671313294042149, 'R2': 0.9149068032512901}\n",
      "{'Model': 'ADA', 'Time(s)': 479.0085141658783, 'RMSE': 20.69933365484366, 'R2': 0.18080951919407573}\n",
      "{'Model': 'GBR', 'Time(s)': 654.2590267658234, 'RMSE': 16.13645052678724, 'R2': 0.5021618334231359}\n",
      "{'Model': 'MLP', 'Time(s)': 3093.824917078018, 'RMSE': 23.175210809774192, 'R2': -0.02687966476099124}\n",
      "{'Model': 'XGB', 'Time(s)': 16.0857515335083, 'RMSE': 8.440437858983694, 'R2': 0.8637921553844169}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2534\n",
      "[LightGBM] [Info] Number of data points in the train set: 1978368, number of used features: 114\n",
      "[LightGBM] [Info] Start training from score 23.131690\n",
      "{'Model': 'LGBM', 'Time(s)': 10.801563739776611, 'RMSE': 10.015103271636756, 'R2': 0.808228956766065}\n",
      "{'Model': 'CAT', 'Time(s)': 206.77506852149963, 'RMSE': 6.727468954094148, 'R2': 0.9134682331413181}\n",
      "\n",
      "=== ëª¨ë¸ë³„ ì‹¤í–‰ ì‹œê°„Â·ì„±ëŠ¥ ë¹„êµ ===\n",
      "  Model      Time(s)       RMSE        R2\n",
      "0   ARD   112.843321  17.954548  0.383659\n",
      "1    RF   786.761838   6.940728  0.907895\n",
      "2    ET   737.576219   6.671313  0.914907\n",
      "3   ADA   479.008514  20.699334  0.180810\n",
      "4   GBR   654.259027  16.136451  0.502162\n",
      "5   MLP  3093.824917  23.175211 -0.026880\n",
      "6   XGB    16.085752   8.440438  0.863792\n",
      "7  LGBM    10.801564  10.015103  0.808229\n",
      "8   CAT   206.775069   6.727469  0.913468\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ì „ì²˜ë¦¬Â·í‰ê°€ìš©\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics      import mean_squared_error, r2_score\n",
    "\n",
    "# â”€â”€ ì„ í˜• ê³„ì—´ íšŒê·€ ëª¨ë¸ â”€â”€\n",
    "from sklearn.linear_model import (\n",
    "    ARDRegression,       # ard\n",
    "    TheilSenRegressor,   # tr\n",
    "    RANSACRegressor      # ransac\n",
    ")\n",
    "\n",
    "# â”€â”€ ì»¤ë„ & ê±°ë¦¬ ê¸°ë°˜ â”€â”€ ìš©ëŸ‰&ì‹œê°„ìœ¼ë¡œ ì œì™¸\n",
    "# from sklearn.kernel_ridge import KernelRidge   # kr\n",
    "# from sklearn.svm           import SVR           # svm\n",
    "# from sklearn.neighbors     import KNeighborsRegressor  # knn\n",
    "\n",
    "# â”€â”€ íŠ¸ë¦¬ & ì•™ìƒë¸” â”€â”€\n",
    "from sklearn.tree          import DecisionTreeRegressor     # dt\n",
    "from sklearn.ensemble      import (\n",
    "    RandomForestRegressor,  # rf\n",
    "    ExtraTreesRegressor,    # et\n",
    "    AdaBoostRegressor,      # ada\n",
    "    GradientBoostingRegressor  # gbr\n",
    ")\n",
    "\n",
    "# â”€â”€ ì‹ ê²½ë§ & ë¶€ìŠ¤íŒ… â”€â”€\n",
    "from sklearn.neural_network import MLPRegressor     # mlp\n",
    "from xgboost                 import XGBRegressor    # xgboost\n",
    "from lightgbm                import LGBMRegressor   # lightgbm\n",
    "from catboost                import CatBoostRegressor  # catboost\n",
    "\n",
    "results = []\n",
    "\n",
    "# ARD\n",
    "ard = ARDRegression()\n",
    "res = evaluate_model('ARD', ard, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('ARD: ', res)\n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "res = evaluate_model('RF', rf, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('RandomForest: ', res)\n",
    "\n",
    "# ExtraTrees\n",
    "et = ExtraTreesRegressor(n_jobs=-1, random_state=42)\n",
    "res = evaluate_model('ET', et, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('ExtraTrees: ', res)\n",
    "\n",
    "# AdaBoost\n",
    "ada = AdaBoostRegressor(random_state=42)\n",
    "res = evaluate_model('ADA', ada, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('AdaBoost: ', res)\n",
    "\n",
    "# GradientBoosting\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "res = evaluate_model('GBR', gbr, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('GradientBoosting: ', res)\n",
    "\n",
    "# MLP\n",
    "mlp = MLPRegressor(random_state=42)\n",
    "res = evaluate_model('MLP', mlp, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('MLP: ', res)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBRegressor(tree_method='hist', n_jobs=-1, random_state=42)\n",
    "res = evaluate_model('XGB', xgb, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('XGBoost: ', res)\n",
    "\n",
    "# LightGBM\n",
    "lgbm = LGBMRegressor(n_jobs=-1, random_state=42)\n",
    "res = evaluate_model('LGBM', lgbm, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('LightGBM: ', res)\n",
    "\n",
    "# CatBoost\n",
    "cat = CatBoostRegressor(verbose=0, random_state=42)\n",
    "res = evaluate_model('CAT', cat, X_train, y_train, X_val, y_val)\n",
    "results.append(res)\n",
    "print('CatBoost: ', res)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 3) ìš”ì•½ ì¶œë ¥\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== ëª¨ë¸ë³„ ì‹¤í–‰ ì‹œê°„Â·ì„±ëŠ¥ ë¹„êµ ===\")\n",
    "print(results_df)\n",
    "\n",
    "# (ì›í•˜ë©´ CSVë¡œ ì €ì¥)\n",
    "os.makedirs('./test', exist_ok=True)\n",
    "results_df.to_csv('./test/model_time_performance_line7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c0442d-7929-4b34-8051-00002e7f7335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4068c92eeada4d3b9c610f94c9326356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                             | 1/15 [00:39<09:11, 39.36s/it]\u001b[A\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                            | 7/15 [00:40<00:34,  4.28s/it]\u001b[A\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                      | 8/15 [00:40<00:25,  3.60s/it]\u001b[A\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 9/15 [00:42<00:19,  3.23s/it]\u001b[A\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 12/15 [00:42<00:05,  1.78s/it]\u001b[A\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 13/15 [00:43<00:03,  1.52s/it]\u001b[A\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 14/15 [00:43<00:01,  1.27s/it]\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:43<00:00,  2.93s/it]\u001b[A\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x0000020D4D51EE10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\samsung\\anaconda3\\envs\\py311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df23 = pd.read_csv('./data/train_subway23.csv', encoding='CP949')\n",
    "df22 = pd.read_csv('./data/train_subway22.csv', encoding='CP949')\n",
    "df21 = pd.read_csv('./data/train_subway21.csv', encoding='CP949')\n",
    "df = pd.concat([df21, df22, df23], axis=0, ignore_index=True)\n",
    "\n",
    "del df23\n",
    "del df22\n",
    "del df21\n",
    "\n",
    "# í”„ë¡œíŒŒì¼ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "from pycaret.regression import *\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(\n",
    "    df,\n",
    "    title=\"My Data Profiling Report\",  # ë¦¬í¬íŠ¸ ì œëª©\n",
    "    explorative=True,                  # ìì„¸í•œ ë¶„ì„ ëª¨ë“œ\n",
    "    minimal=False                       # ìµœì†Œ ë¦¬í¬íŠ¸ ëª¨ë“œ í•´ì œ\n",
    ")\n",
    "\n",
    "# 3) ê²°ê³¼ë¥¼ HTML íŒŒì¼ë¡œ ì €ì¥\n",
    "profile.to_file(\"data_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74847eac-4c8d-46f7-bdd7-739cc973492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ [Line 7] AutoML ì‹œì‘\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m test_line = test[test[\u001b[33m'\u001b[39m\u001b[33mLine\u001b[39m\u001b[33m'\u001b[39m] == line].copy()\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# 2) PyCaret ì„¸ì…˜ ì„¤ì •\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m exp = \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCongestion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTM\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstation_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_selection_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munivariate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_features_to_select\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\n\u001b[32m     50\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# 3) ëª¨ë¸ ë¹„êµ ë° ì„ íƒ (ë„¤ ê°€ì§€ ëª¨ë¸ë§Œ)\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.redirect_stdout(_silencer), contextlib.redirect_stderr(_silencer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\regression\\functional.py:593\u001b[39m, in \u001b[36msetup\u001b[39m\u001b[34m(data, data_func, target, index, train_size, test_data, ordinal_features, numeric_features, categorical_features, date_features, text_features, ignore_features, keep_features, preprocess, create_date_columns, imputation_type, numeric_imputation, categorical_imputation, iterative_imputation_iters, numeric_iterative_imputer, categorical_iterative_imputer, text_features_method, max_encoding_ohe, encoding_method, rare_to_value, rare_value, polynomial_features, polynomial_degree, low_variance_threshold, group_features, drop_groups, remove_multicollinearity, multicollinearity_threshold, bin_numeric_features, remove_outliers, outliers_method, outliers_threshold, transformation, transformation_method, normalize, normalize_method, pca, pca_method, pca_components, feature_selection, feature_selection_method, feature_selection_estimator, n_features_to_select, transform_target, transform_target_method, custom_pipeline, custom_pipeline_position, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, html, session_id, system_log, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, verbose, memory, profile, profile_kwargs)\u001b[39m\n\u001b[32m    591\u001b[39m exp = _EXPERIMENT_CLASS()\n\u001b[32m    592\u001b[39m set_current_experiment(exp)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mordinal_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordinal_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_date_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_date_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimputation_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimputation_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumeric_imputation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_imputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_imputation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_imputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43miterative_imputation_iters\u001b[49m\u001b[43m=\u001b[49m\u001b[43miterative_imputation_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumeric_iterative_imputer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_iterative_imputer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_iterative_imputer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_iterative_imputer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_features_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_features_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_encoding_ohe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_encoding_ohe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrare_to_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrare_to_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrare_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrare_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolynomial_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolynomial_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolynomial_degree\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolynomial_degree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_variance_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_variance_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_groups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremove_multicollinearity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremove_multicollinearity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulticollinearity_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulticollinearity_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbin_numeric_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbin_numeric_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremove_outliers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremove_outliers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutliers_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutliers_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutliers_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutliers_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformation_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpca\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpca\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpca_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpca_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpca_components\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpca_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_selection_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_selection_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_selection_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_features_to_select\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_features_to_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_target\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_target_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform_target_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_pipeline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_pipeline_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_pipeline_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_split_shuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_split_shuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_split_stratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_split_stratify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_shuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_shuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_groups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43msystem_log\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_experiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_experiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_plots\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_plots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_profile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_profile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprofile_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprofile_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\regression\\oop.py:742\u001b[39m, in \u001b[36mRegressionExperiment.setup\u001b[39m\u001b[34m(self, data, data_func, target, index, train_size, test_data, ordinal_features, numeric_features, categorical_features, date_features, text_features, ignore_features, keep_features, preprocess, create_date_columns, imputation_type, numeric_imputation, categorical_imputation, iterative_imputation_iters, numeric_iterative_imputer, categorical_iterative_imputer, text_features_method, max_encoding_ohe, encoding_method, rare_to_value, rare_value, polynomial_features, polynomial_degree, low_variance_threshold, group_features, drop_groups, remove_multicollinearity, multicollinearity_threshold, bin_numeric_features, remove_outliers, outliers_method, outliers_threshold, transformation, transformation_method, normalize, normalize_method, pca, pca_method, pca_components, feature_selection, feature_selection_method, feature_selection_estimator, n_features_to_select, transform_target, transform_target_method, custom_pipeline, custom_pipeline_position, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, html, session_id, system_log, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, engine, verbose, memory, profile, profile_kwargs)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_train_test(\n\u001b[32m    726\u001b[39m     train_size=train_size,\n\u001b[32m    727\u001b[39m     test_data=test_data,\n\u001b[32m    728\u001b[39m     data_split_stratify=data_split_stratify,\n\u001b[32m    729\u001b[39m     data_split_shuffle=data_split_shuffle,\n\u001b[32m    730\u001b[39m )\n\u001b[32m    732\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_column_types(\n\u001b[32m    733\u001b[39m     ordinal_features=ordinal_features,\n\u001b[32m    734\u001b[39m     numeric_features=numeric_features,\n\u001b[32m   (...)\u001b[39m\u001b[32m    739\u001b[39m     keep_features=keep_features,\n\u001b[32m    740\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_exp_model_engines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontainer_default_engines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_container_default_engines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Preprocessing ============================================ >>\u001b[39;00m\n\u001b[32m    748\u001b[39m \n\u001b[32m    749\u001b[39m \u001b[38;5;66;03m# Initialize empty pipeline\u001b[39;00m\n\u001b[32m    750\u001b[39m \u001b[38;5;28mself\u001b[39m.pipeline = InternalPipeline(\n\u001b[32m    751\u001b[39m     steps=[(\u001b[33m\"\u001b[39m\u001b[33mplaceholder\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)],\n\u001b[32m    752\u001b[39m     memory=\u001b[38;5;28mself\u001b[39m.memory,\n\u001b[32m    753\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:2849\u001b[39m, in \u001b[36m_TabularExperiment._set_exp_model_engines\u001b[39m\u001b[34m(self, container_default_engines, engine)\u001b[39m\n\u001b[32m   2846\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m container_default_engines:\n\u001b[32m   2847\u001b[39m     \u001b[38;5;66;03m# If provided by user, then use that, else get from the defaults\u001b[39;00m\n\u001b[32m   2848\u001b[39m     eng = engine.get(key, container_default_engines.get(key))\n\u001b[32m-> \u001b[39m\u001b[32m2849\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43meng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseverity\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:2815\u001b[39m, in \u001b[36m_TabularExperiment._set_engine\u001b[39m\u001b[34m(self, estimator, engine, severity)\u001b[39m\n\u001b[32m   2810\u001b[39m     \u001b[38;5;28mself\u001b[39m.logger.info(\n\u001b[32m   2811\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEngine successfully changes for model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2812\u001b[39m     )\n\u001b[32m   2814\u001b[39m \u001b[38;5;66;03m# Need to do this, else internal class variables are not reset with new engine.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2815\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:2705\u001b[39m, in \u001b[36m_TabularExperiment._set_all_models\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2697\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_all_models\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33m_TabularExperiment\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2698\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Set all available models\u001b[39;00m\n\u001b[32m   2699\u001b[39m \n\u001b[32m   2700\u001b[39m \u001b[33;03m    Returns\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2703\u001b[39m \u001b[33;03m        The experiment object to allow chaining of methods\u001b[39;00m\n\u001b[32m   2704\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2705\u001b[39m     \u001b[38;5;28mself\u001b[39m._all_models, \u001b[38;5;28mself\u001b[39m._all_models_internal = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2706\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\regression\\oop.py:67\u001b[39m, in \u001b[36mRegressionExperiment._get_models\u001b[39m\u001b[34m(self, raise_errors)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_models\u001b[39m(\u001b[38;5;28mself\u001b[39m, raise_errors: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Tuple[\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[32m     60\u001b[39m     all_models = {\n\u001b[32m     61\u001b[39m         k: v\n\u001b[32m     62\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m get_all_model_containers(\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v.is_special\n\u001b[32m     66\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     all_models_internal = \u001b[43mget_all_model_containers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m all_models, all_models_internal\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\containers\\models\\regression.py:1996\u001b[39m, in \u001b[36mget_all_model_containers\u001b[39m\u001b[34m(experiment, raise_errors)\u001b[39m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_all_model_containers\u001b[39m(\n\u001b[32m   1994\u001b[39m     experiment: Any, raise_errors: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1995\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, RegressorContainer]:\n\u001b[32m-> \u001b[39m\u001b[32m1996\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpycaret\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontainers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbase_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_all_containers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1997\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRegressorContainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_errors\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\containers\\base_container.py:119\u001b[39m, in \u001b[36mget_all_containers\u001b[39m\u001b[34m(container_globals, experiment, type_var, raise_errors)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mactive\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj.active:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m instance = \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance.active:\n\u001b[32m    121\u001b[39m     model_containers.append(instance)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\containers\\models\\regression.py:1000\u001b[39m, in \u001b[36mSVRContainer.__init__\u001b[39m\u001b[34m(self, experiment)\u001b[39m\n\u001b[32m    997\u001b[39m gpu_imported = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    999\u001b[39m \u001b[38;5;28mid\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33msvm\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_engine_related_vars\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_allowed_engines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mALL_ALLOWED_ENGINES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33msklearn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1005\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVR\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\containers\\models\\base_model.py:183\u001b[39m, in \u001b[36mModelContainer._set_engine_related_vars\u001b[39m\u001b[34m(self, id, all_allowed_engines, experiment)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28mself\u001b[39m.allowed_engines = get_allowed_engines(\n\u001b[32m    180\u001b[39m     estimator=\u001b[38;5;28mid\u001b[39m, all_allowed_engines=all_allowed_engines\n\u001b[32m    181\u001b[39m )\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.default_engine = \u001b[38;5;28mself\u001b[39m.allowed_engines[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_engine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseverity\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\containers\\models\\base_model.py:132\u001b[39m, in \u001b[36mModelContainer._set_engine\u001b[39m\u001b[34m(self, id, experiment, severity)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_engine\u001b[39m(\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    105\u001b[39m     \u001b[38;5;28mid\u001b[39m: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    106\u001b[39m     experiment: _PyCaretExperiment,\n\u001b[32m    107\u001b[39m     severity: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    108\u001b[39m ):\n\u001b[32m    109\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sets the engine to use for a particular model based on what is set in\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33;03m    the experiment.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m \u001b[33;03m        (2) If the value of \"severity\" is not one of the allowed values\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     engine_to_use = \u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# If not specified, use the default engine\u001b[39;00m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m engine_to_use \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:2750\u001b[39m, in \u001b[36m_TabularExperiment.get_engine\u001b[39m\u001b[34m(self, estimator)\u001b[39m\n\u001b[32m   2745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2746\u001b[39m     msg = (\n\u001b[32m   2747\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEngine for model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has not been set explicitly, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2748\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhence returning None.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2749\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2750\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2752\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\logging\\__init__.py:1489\u001b[39m, in \u001b[36mLogger.info\u001b[39m\u001b[34m(self, msg, *args, **kwargs)\u001b[39m\n\u001b[32m   1480\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1481\u001b[39m \u001b[33;03mLog 'msg % args' with severity 'INFO'.\u001b[39;00m\n\u001b[32m   1482\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1486\u001b[39m \u001b[33;03mlogger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\u001b[39;00m\n\u001b[32m   1487\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1488\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.isEnabledFor(INFO):\n\u001b[32m-> \u001b[39m\u001b[32m1489\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINFO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\logging\\__init__.py:1634\u001b[39m, in \u001b[36mLogger._log\u001b[39m\u001b[34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001b[39m\n\u001b[32m   1631\u001b[39m         exc_info = sys.exc_info()\n\u001b[32m   1632\u001b[39m record = \u001b[38;5;28mself\u001b[39m.makeRecord(\u001b[38;5;28mself\u001b[39m.name, level, fn, lno, msg, args,\n\u001b[32m   1633\u001b[39m                          exc_info, func, extra, sinfo)\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\logging\\__init__.py:1644\u001b[39m, in \u001b[36mLogger.handle\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m   1637\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1638\u001b[39m \u001b[33;03mCall the handlers for the specified record.\u001b[39;00m\n\u001b[32m   1639\u001b[39m \n\u001b[32m   1640\u001b[39m \u001b[33;03mThis method is used for unpickled records received from a socket, as\u001b[39;00m\n\u001b[32m   1641\u001b[39m \u001b[33;03mwell as those created locally. Logger-level filtering is applied.\u001b[39;00m\n\u001b[32m   1642\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1643\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disabled) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filter(record):\n\u001b[32m-> \u001b[39m\u001b[32m1644\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallHandlers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\logging\\__init__.py:1706\u001b[39m, in \u001b[36mLogger.callHandlers\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m   1704\u001b[39m     found = found + \u001b[32m1\u001b[39m\n\u001b[32m   1705\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m record.levelno >= hdlr.level:\n\u001b[32m-> \u001b[39m\u001b[32m1706\u001b[39m         \u001b[43mhdlr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m c.propagate:\n\u001b[32m   1708\u001b[39m     c = \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m#break out\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\logging\\__init__.py:978\u001b[39m, in \u001b[36mHandler.handle\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28mself\u001b[39m.acquire()\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    980\u001b[39m     \u001b[38;5;28mself\u001b[39m.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\logging\\__init__.py:1230\u001b[39m, in \u001b[36mFileHandler.emit\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m   1228\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = \u001b[38;5;28mself\u001b[39m._open()\n\u001b[32m   1229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n\u001b[32m-> \u001b[39m\u001b[32m1230\u001b[39m     \u001b[43mStreamHandler\u001b[49m\u001b[43m.\u001b[49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\logging\\__init__.py:1114\u001b[39m, in \u001b[36mStreamHandler.emit\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m   1112\u001b[39m     \u001b[38;5;66;03m# issue 35046: merged two stream.writes into one.\u001b[39;00m\n\u001b[32m   1113\u001b[39m     stream.write(msg + \u001b[38;5;28mself\u001b[39m.terminator)\n\u001b[32m-> \u001b[39m\u001b[32m1114\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m:  \u001b[38;5;66;03m# See issue 36272\u001b[39;00m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\logging\\__init__.py:1094\u001b[39m, in \u001b[36mStreamHandler.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.stream, \u001b[33m\"\u001b[39m\u001b[33mflush\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream.flush()\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28mself\u001b[39m.release()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['LIGHTGBM_VERBOSE'] = '0'\n",
    "import io, contextlib\n",
    "\n",
    "# 1) ë¹ˆ ìŠ¤íŠ¸ë¦¼ ìƒì„±\n",
    "_silencer = io.StringIO()\n",
    "from pycaret.regression import (\n",
    "    setup,\n",
    "    compare_models,\n",
    "    finalize_model,\n",
    "    predict_model,\n",
    "    save_model\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "os.makedirs('./models_pycaret', exist_ok=True)\n",
    "\n",
    "all_predictions = []\n",
    "metrics = []\n",
    "\n",
    "# ë¹„êµí•  ëª¨ë¸ ëª©ë¡ ì •ì˜\n",
    "include_models = ['rf'       # RandomForestRegressor\n",
    "                  #'xgboost',  # XGBRegressor\n",
    "                  #'catboost', # CatBoostRegressor\n",
    "                  #'et'\n",
    "                 ]       # ExtraTreesRegressor\n",
    "\n",
    "line = 7\n",
    "print(f\"\\nğŸ¯ [Line {line}] AutoML ì‹œì‘\")\n",
    "\n",
    "# 1) ë°ì´í„° ë¶„ë¦¬\n",
    "train = df[df['Line'] == line].copy()\n",
    "test_line = test[test['Line'] == line].copy()\n",
    "\n",
    "# 2) PyCaret ì„¸ì…˜ ì„¤ì •\n",
    "exp = setup(\n",
    "    data=train,\n",
    "    target='Congestion',\n",
    "    session_id=42,\n",
    "    train_size=0.8,\n",
    "    use_gpu=True,\n",
    "    verbose=False,\n",
    "    html=False,\n",
    "    ignore_features=['TM', 'station_name'],\n",
    "    feature_selection=False,\n",
    "    feature_selection_method='univariate',\n",
    "    n_features_to_select=30\n",
    ")\n",
    "\n",
    "# 3) ëª¨ë¸ ë¹„êµ ë° ì„ íƒ (ë„¤ ê°€ì§€ ëª¨ë¸ë§Œ)\n",
    "with contextlib.redirect_stdout(_silencer), contextlib.redirect_stderr(_silencer):\n",
    "    best = compare_models(\n",
    "        include=include_models,\n",
    "        n_select=1,\n",
    "        verbose=False\n",
    "    )\n",
    "# 4) ìµœì¢… ëª¨ë¸ ê³ ì •\n",
    "final_model = finalize_model(best)\n",
    "\n",
    "# 5) ì €ì¥\n",
    "model_name = best.__class__.__name__.lower()\n",
    "save_model(final_model, f'./models_pycaret/{model_name}_line{line}')\n",
    "\n",
    "# 6) ê²€ì¦ ì„±ëŠ¥ ì‚°ì¶œ (ê°„ê²° ì¶œë ¥)\n",
    "val_pred = predict_model(final_model)\n",
    "\n",
    "# â‘  ì›ë³¸ train DataFrameì˜ ì»¬ëŸ¼ ëª©ë¡\n",
    "orig_cols = set(train.columns)\n",
    "\n",
    "# â‘¡ ì˜ˆì¸¡ê°’ ì»¬ëŸ¼ ìë™ íƒìƒ‰\n",
    "#    trainì— ì—†ê³ , íƒ€ê¹ƒ('Congestion')ë„ ì•„ë‹Œ ì²« ë²ˆì§¸ ìˆ«ìí˜• ì»¬ëŸ¼ì„ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ê°„ì£¼\n",
    "cand = [\n",
    "    c for c in val_pred.columns \n",
    "    if c not in orig_cols \n",
    "    and c != 'Congestion' \n",
    "    and pd.api.types.is_numeric_dtype(val_pred[c])\n",
    "]\n",
    "pred_col = cand[0]  # ë³´í†µ í•œ ê°œë§Œ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "\n",
    "# â‘¢ RMSEì™€ RÂ² ê³„ì‚°\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "rmse = mean_squared_error(\n",
    "    val_pred['Congestion'], \n",
    "    val_pred[pred_col], \n",
    "    squared=False\n",
    ")\n",
    "r2   = r2_score(\n",
    "    val_pred['Congestion'], \n",
    "    val_pred[pred_col]\n",
    ")\n",
    "\n",
    "# â‘£ ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥\n",
    "metrics.append({\n",
    "    'Line':      line,\n",
    "    'Model':     model_name,\n",
    "    'RMSE':      rmse,\n",
    "    'R2':        r2\n",
    "})\n",
    "print(f\"  â†’ Line {line} | ëª¨ë¸: {model_name} | RMSE: {rmse:.4f} | RÂ²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66552785-e730-45de-b30f-d4719f03d9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
